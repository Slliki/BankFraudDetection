{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-19T07:56:27.051643Z",
     "start_time": "2024-07-19T07:56:26.649482Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from sklearn.metrics import make_scorer, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from aequitas.group import Group\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.fairness import Fairness\n",
    "from sklearn.metrics import roc_auc_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T18:00:42.349380Z",
     "start_time": "2024-07-20T18:00:40.731952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lightgbm as lgb\n",
    "print(lgb.__version__)\n",
    "\n",
    "# 测试LightGBM的GPU支持\n",
    "params = {\n",
    "    'boosting_type': 'gbrt',\n",
    "    'objective': 'binary',\n",
    "    'device': 'gpu',\n",
    "    'gpu_platform_id': 0,\n",
    "    'gpu_device_id': 0\n",
    "}\n",
    "\n",
    "# 创建一个简单的数据集并训练模型\n",
    "import numpy as np\n",
    "\n",
    "# 创建数据\n",
    "X_train = np.random.rand(100, 10)\n",
    "y_train = np.random.randint(2, size=100)\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "# 训练模型\n",
    "bst = lgb.train(params, train_data, num_boost_round=10)\n"
   ],
   "id": "9cdebf2df03ccdc7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4.0\n",
      "[LightGBM] [Info] Number of positive: 44, number of negative: 56\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mLightGBMError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 23\u001B[0m\n\u001B[0;32m     20\u001B[0m train_data \u001B[38;5;241m=\u001B[39m lgb\u001B[38;5;241m.\u001B[39mDataset(X_train, label\u001B[38;5;241m=\u001B[39my_train)\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# 训练模型\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m bst \u001B[38;5;241m=\u001B[39m \u001B[43mlgb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_boost_round\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\lightgbm\\engine.py:282\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001B[0m\n\u001B[0;32m    280\u001B[0m \u001B[38;5;66;03m# construct booster\u001B[39;00m\n\u001B[0;32m    281\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 282\u001B[0m     booster \u001B[38;5;241m=\u001B[39m \u001B[43mBooster\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    283\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_valid_contain_train:\n\u001B[0;32m    284\u001B[0m         booster\u001B[38;5;241m.\u001B[39mset_train_data_name(train_data_name)\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\lightgbm\\basic.py:3631\u001B[0m, in \u001B[0;36mBooster.__init__\u001B[1;34m(self, params, train_set, model_file, model_str)\u001B[0m\n\u001B[0;32m   3629\u001B[0m params\u001B[38;5;241m.\u001B[39mupdate(train_set\u001B[38;5;241m.\u001B[39mget_params())\n\u001B[0;32m   3630\u001B[0m params_str \u001B[38;5;241m=\u001B[39m _param_dict_to_str(params)\n\u001B[1;32m-> 3631\u001B[0m \u001B[43m_safe_call\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3632\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLGBM_BoosterCreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3633\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_set\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3634\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_c_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_str\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3635\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3636\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3637\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3638\u001B[0m \u001B[38;5;66;03m# save reference to data\u001B[39;00m\n\u001B[0;32m   3639\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_set \u001B[38;5;241m=\u001B[39m train_set\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\lightgbm\\basic.py:294\u001B[0m, in \u001B[0;36m_safe_call\u001B[1;34m(ret)\u001B[0m\n\u001B[0;32m    286\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Check the return value from C API call.\u001B[39;00m\n\u001B[0;32m    287\u001B[0m \n\u001B[0;32m    288\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    291\u001B[0m \u001B[38;5;124;03m    The return value from C API calls.\u001B[39;00m\n\u001B[0;32m    292\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 294\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m LightGBMError(_LIB\u001B[38;5;241m.\u001B[39mLGBM_GetLastError()\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "\u001B[1;31mLightGBMError\u001B[0m: GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. Load Data and Preprocessing\n",
    "\n",
    "- label encoding: deal with categorical features;\n",
    "    - one hot encoding: 生成更多特征\n",
    "- pick the features as X and the target as y;\n",
    "- split the data into training and testing sets; (选择前六个月0-5作为训练集，这是作者提到的一个实践方式）\n",
    "- scale the numerical features(MinMaxScaler);由于大量特征的分布并不趋于正态，有大量异常值等，选择minmax更好\n",
    "- store the indices of the categorical features(for later use in SMOTE-NC);"
   ],
   "id": "cbbe994652bf4ab7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.1 Encoding Categorical Features",
   "id": "103cf06d80d222b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T07:56:30.398867Z",
     "start_time": "2024-07-19T07:56:28.283509Z"
    }
   },
   "cell_type": "code",
   "source": "base = pd.read_csv('datasets/processed_base.csv')  # no missing values. dropped 3 cols",
   "id": "4ccfeea281ed63ed",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T07:56:31.422370Z",
     "start_time": "2024-07-19T07:56:30.950838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# one-hot encoding\n",
    "def one_hot_encoding(data):\n",
    "    # 需要进行One-Hot Encoding的分类变量\n",
    "    categorical_features = ['payment_type', 'employment_status', 'housing_status', 'source', 'device_os']\n",
    "    \n",
    "    # 使用pd.get_dummies进行One-Hot Encoding\n",
    "    # drop_first=True表示删除第一个类别，避免多重共线性,同时避免引入不必要的特征并且保留了所有信息\n",
    "    # 此时先用False保留所有特征，后续建立模型时候可以选择drop_first=True来避免多重共线性并减少特征数量\n",
    "    data_encoded = pd.get_dummies(data, columns=categorical_features,drop_first=True)\n",
    "    \n",
    "    # 找出新生成的 One-Hot 编码列\n",
    "    encoded_columns = data_encoded.columns.difference(data.columns)\n",
    "    \n",
    "    # 将 One-Hot 编码列转换为整数类型\n",
    "    data_encoded[encoded_columns] = data_encoded[encoded_columns].astype(int)\n",
    "    \n",
    "    return data_encoded\n",
    "\n",
    "# 示例预处理\n",
    "df = one_hot_encoding(base)\n",
    "df.head()"
   ],
   "id": "8aac58057bd0192",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   fraud_bool  income  name_email_similarity  current_address_months_count  \\\n",
       "0           0     0.3               0.986506                          25.0   \n",
       "1           0     0.8               0.617426                          89.0   \n",
       "2           0     0.8               0.996707                          14.0   \n",
       "3           0     0.6               0.475100                          14.0   \n",
       "4           0     0.9               0.842307                          29.0   \n",
       "\n",
       "   customer_age  days_since_request  zip_count_4w   velocity_6h  velocity_24h  \\\n",
       "0            40            0.006735          1059  13096.035018   7850.955007   \n",
       "1            20            0.010095          1658   9223.283431   5745.251481   \n",
       "2            40            0.012316          1095   4471.472149   5471.988958   \n",
       "3            30            0.006991          3483  14431.993621   6755.344479   \n",
       "4            40            5.742626          2339   7601.511579   5124.046930   \n",
       "\n",
       "   velocity_4w  ...  housing_status_BC  housing_status_BD  housing_status_BE  \\\n",
       "0  6742.080561  ...                  1                  0                  0   \n",
       "1  5941.664859  ...                  1                  0                  0   \n",
       "2  5992.555113  ...                  1                  0                  0   \n",
       "3  5970.336831  ...                  1                  0                  0   \n",
       "4  5940.734212  ...                  1                  0                  0   \n",
       "\n",
       "   housing_status_BF  housing_status_BG  source_TELEAPP  device_os_macintosh  \\\n",
       "0                  0                  0               0                    0   \n",
       "1                  0                  0               0                    0   \n",
       "2                  0                  0               0                    0   \n",
       "3                  0                  0               0                    0   \n",
       "4                  0                  0               0                    0   \n",
       "\n",
       "   device_os_other  device_os_windows  device_os_x11  \n",
       "0                0                  0              0  \n",
       "1                1                  0              0  \n",
       "2                0                  1              0  \n",
       "3                0                  0              0  \n",
       "4                1                  0              0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud_bool</th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>velocity_6h</th>\n",
       "      <th>velocity_24h</th>\n",
       "      <th>velocity_4w</th>\n",
       "      <th>...</th>\n",
       "      <th>housing_status_BC</th>\n",
       "      <th>housing_status_BD</th>\n",
       "      <th>housing_status_BE</th>\n",
       "      <th>housing_status_BF</th>\n",
       "      <th>housing_status_BG</th>\n",
       "      <th>source_TELEAPP</th>\n",
       "      <th>device_os_macintosh</th>\n",
       "      <th>device_os_other</th>\n",
       "      <th>device_os_windows</th>\n",
       "      <th>device_os_x11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.986506</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>1059</td>\n",
       "      <td>13096.035018</td>\n",
       "      <td>7850.955007</td>\n",
       "      <td>6742.080561</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.617426</td>\n",
       "      <td>89.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010095</td>\n",
       "      <td>1658</td>\n",
       "      <td>9223.283431</td>\n",
       "      <td>5745.251481</td>\n",
       "      <td>5941.664859</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.996707</td>\n",
       "      <td>14.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>1095</td>\n",
       "      <td>4471.472149</td>\n",
       "      <td>5471.988958</td>\n",
       "      <td>5992.555113</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>3483</td>\n",
       "      <td>14431.993621</td>\n",
       "      <td>6755.344479</td>\n",
       "      <td>5970.336831</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.842307</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40</td>\n",
       "      <td>5.742626</td>\n",
       "      <td>2339</td>\n",
       "      <td>7601.511579</td>\n",
       "      <td>5124.046930</td>\n",
       "      <td>5940.734212</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# labnel encoding\n",
    "def label_encoding(data):\n",
    "    # 需要进行Label Encoding的分类变量\n",
    "    categorical_features = ['payment_type', 'employment_status', 'housing_status', 'source', 'device_os']\n",
    "    \n",
    "    # 创建 LabelEncoder 实例\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    # 对每个分类变量进行 Label Encoding\n",
    "    for feature in categorical_features:\n",
    "        data[feature] = label_encoder.fit_transform(data[feature])\n",
    "    \n",
    "    return data\n",
    "\n",
    "df = label_encoding(base)"
   ],
   "id": "d9565ec361c8a496"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.2 Train test split & Resampling\n",
    "可以选择前六个月为训练集，剩余为测试集，也可以直接随机split（base没有时间bias）\n",
    "\n",
    "- RandomUnderSampler: 随机下采样\n",
    "- NearMiss: 通过保留与最近邻居类别不同的样本来下采样\n",
    "\n",
    "Now apply the undersampling to the training set (0:1 = 90:1-->20:1) ,later we will apply smote on the resampled train set in cross validation to make it balanced.\n",
    "\n",
    "- Original train set: Majority class: 90, Minority class: 1\n",
    "- Under-sampled train set: Majority class: 20, Minority class: 1\n",
    "- Over-sampled train set: Majority class: 1, Minority class: 1  BALANCED"
   ],
   "id": "6d8e0717a1de3b22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:35:58.181702Z",
     "start_time": "2024-07-19T05:35:57.422212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 查看month<6的数据\n",
    "# df[df['month'] < 6] # 790334\n",
    "\n",
    "# 使用前六个月作为训练集,indices 为790334\n",
    "train_indices = range(790335)\n",
    "test_indices = range(790335, len(df))\n",
    "\n",
    "# 使用loc方法根据索引范围分割数据\n",
    "x_train = df.loc[train_indices, df.columns != 'fraud_bool']\n",
    "y_train = df.loc[train_indices, 'fraud_bool']\n",
    "x_test = df.loc[test_indices, df.columns != 'fraud_bool']\n",
    "y_test = df.loc[test_indices, 'fraud_bool']"
   ],
   "id": "c1cdd21f34870ca4",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T07:56:36.811445Z",
     "start_time": "2024-07-19T07:56:36.457647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train test split random\n",
    "X = df.drop(columns='fraud_bool')\n",
    "y = df['fraud_bool']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42, shuffle=True)"
   ],
   "id": "10b1796281dad7b4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T07:56:38.337153Z",
     "start_time": "2024-07-19T07:56:38.324272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 下采样函数\n",
    "def undersample_majority_class(x, y, ratio=10, strategy='random'):\n",
    "\n",
    "    minority_class_size = np.sum(y == 1)\n",
    "    majority_class_size = minority_class_size * ratio\n",
    "    \n",
    "    if strategy == 'random':\n",
    "        undersample = RandomUnderSampler(sampling_strategy={0: majority_class_size, 1: minority_class_size}, random_state=42)\n",
    "    elif strategy == 'nearmiss':\n",
    "        undersample = NearMiss(sampling_strategy={0: majority_class_size, 1: minority_class_size}, n_jobs=-1)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported strategy. Use 'random' or 'nearmiss'.\")\n",
    "    \n",
    "    x_resampled, y_resampled = undersample.fit_resample(x, y)\n",
    "    return x_resampled, y_resampled"
   ],
   "id": "8993165d81747e10",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T07:56:48.106733Z",
     "start_time": "2024-07-19T07:56:40.323258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 若直接对整个数据集进行下采样。该方法不会导致数据泄露问题，因为只是移除某些样本，但是实际情况可能不太符合。\n",
    "x_nm,y_nm=undersample_majority_class(x_train,y_train,ratio=10,strategy='nearmiss')\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_nm, y_nm, test_size=0.2, random_state=42, shuffle=True)\n",
    "y_train.value_counts(),y_test.value_counts()"
   ],
   "id": "beea59a78b50f6fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fraud_bool\n",
       " 0    83524\n",
       " 1     8427\n",
       " Name: count, dtype: int64,\n",
       " fraud_bool\n",
       " 0    20966\n",
       " 1     2022\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.4 Scaling",
   "id": "29afd85c642b57d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T06:58:32.300458Z",
     "start_time": "2024-07-19T06:58:29.946331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 筛选出二进制特征\n",
    "binary_features_name = [\n",
    "    'email_is_free',\n",
    "    'phone_home_valid',\n",
    "    'phone_mobile_valid',\n",
    "    'has_other_cards',\n",
    "    'foreign_request',\n",
    "    'keep_alive_session',\n",
    "    'fraud_bool'\n",
    "]\n",
    "\n",
    "binary_features = df[binary_features_name]\n",
    "\n",
    "# 列出所有的数值型特征\n",
    "# numeric_features_name = df.select_dtypes(include=['number']).columns.tolist()\n",
    "# 去掉二进制特征\n",
    "# numeric_features_name = [col for col in numeric_features_name if col not in binary_features_name]\n",
    "\n",
    "numeric_features_name=[x for x in df.columns if df[x].nunique() >= 10]\n",
    "\n",
    "numeric_features = df[numeric_features_name]\n",
    "\n",
    "# 创建 MinMaxScaler 实例\n",
    "numeric_transformer = MinMaxScaler()\n",
    "\n",
    "# 创建 ColumnTransformer\n",
    "preprocessor = ColumnTransformer([('scaled', numeric_transformer, numeric_features_name)], remainder='passthrough')\n",
    "\n",
    "# 在训练集上拟合并转换\n",
    "x_train_scaled = preprocessor.fit_transform(x_train)\n",
    "\n",
    "# 仅转换测试集\n",
    "x_test_scaled = preprocessor.transform(x_test)\n",
    "\n",
    "# 获取列的顺序(colmuntransformer会改变列的顺序)\n",
    "new_columns = numeric_features_name + [col for col in x_train.columns if col not in numeric_features_name]\n",
    "\n",
    "# 转换后的结果通常为 NumPy 数组，将其转换回 DataFrame 并保持列名一致性\n",
    "x_train_scaled = pd.DataFrame(x_train_scaled, columns=new_columns)\n",
    "x_test_scaled = pd.DataFrame(x_test_scaled, columns=new_columns)\n",
    "\n",
    "# 确定分类特征的名称\n",
    "categorical_features_name = [col for col in x_train_scaled.columns if 2 <= x_train_scaled[col].nunique() < 10]\n",
    "\n",
    "# 确定分类特征的索引\n",
    "all_features = list(x_train_scaled.columns)  # 所有特征的名称列表\n",
    "categorical_feature_indices = [i for i, feature in enumerate(all_features) if feature in categorical_features_name]\n",
    "\n",
    "print(\"分类特征名称：\", categorical_features_name)\n",
    "print(\"分类特征索引：\", categorical_feature_indices)"
   ],
   "id": "6a12d6ea2c360ef1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类特征名称： ['income', 'customer_age', 'email_is_free', 'phone_home_valid', 'phone_mobile_valid', 'has_other_cards', 'foreign_request', 'keep_alive_session', 'device_distinct_emails_8w', 'month', 'payment_type_AB', 'payment_type_AC', 'payment_type_AD', 'payment_type_AE', 'employment_status_CB', 'employment_status_CC', 'employment_status_CD', 'employment_status_CE', 'employment_status_CF', 'employment_status_CG', 'housing_status_BB', 'housing_status_BC', 'housing_status_BD', 'housing_status_BE', 'housing_status_BF', 'housing_status_BG', 'source_TELEAPP', 'device_os_macintosh', 'device_os_other', 'device_os_windows', 'device_os_x11']\n",
      "分类特征索引： [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T06:58:37.133035Z",
     "start_time": "2024-07-19T06:58:36.340012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 对标准化后的数据下采样\n",
    "x_train_nm, y_train_nm = undersample_majority_class(x_train_scaled, y_train, ratio=20, strategy='nearmiss')\n",
    "y_train.value_counts(),y_train_nm.value_counts(),y_test.value_counts()"
   ],
   "id": "6217417900bad818",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 对标准化后的数据下采样\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m x_train_nm, y_train_nm \u001B[38;5;241m=\u001B[39m \u001B[43mundersample_majority_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnearmiss\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m y_train\u001B[38;5;241m.\u001B[39mvalue_counts(),y_train_nm\u001B[38;5;241m.\u001B[39mvalue_counts(),y_test\u001B[38;5;241m.\u001B[39mvalue_counts()\n",
      "Cell \u001B[1;32mIn[6], line 14\u001B[0m, in \u001B[0;36mundersample_majority_class\u001B[1;34m(x, y, ratio, strategy)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnsupported strategy. Use \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrandom\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnearmiss\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 14\u001B[0m x_resampled, y_resampled \u001B[38;5;241m=\u001B[39m \u001B[43mundersample\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_resample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x_resampled, y_resampled\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\imblearn\\base.py:208\u001B[0m, in \u001B[0;36mBaseSampler.fit_resample\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Resample the dataset.\u001B[39;00m\n\u001B[0;32m    188\u001B[0m \n\u001B[0;32m    189\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;124;03m    The corresponding label of `X_resampled`.\u001B[39;00m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m--> 208\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_resample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\imblearn\\base.py:112\u001B[0m, in \u001B[0;36mSamplerMixin.fit_resample\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    106\u001B[0m X, y, binarize_y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_X_y(X, y)\n\u001B[0;32m    108\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampling_strategy_ \u001B[38;5;241m=\u001B[39m check_sampling_strategy(\n\u001B[0;32m    109\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampling_strategy, y, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampling_type\n\u001B[0;32m    110\u001B[0m )\n\u001B[1;32m--> 112\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_resample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    114\u001B[0m y_ \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    115\u001B[0m     label_binarize(output[\u001B[38;5;241m1\u001B[39m], classes\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39munique(y)) \u001B[38;5;28;01mif\u001B[39;00m binarize_y \u001B[38;5;28;01melse\u001B[39;00m output[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    116\u001B[0m )\n\u001B[0;32m    118\u001B[0m X_, y_ \u001B[38;5;241m=\u001B[39m arrays_transformer\u001B[38;5;241m.\u001B[39mtransform(output[\u001B[38;5;241m0\u001B[39m], y_)\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:244\u001B[0m, in \u001B[0;36mNearMiss._fit_resample\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    241\u001B[0m y_class \u001B[38;5;241m=\u001B[39m _safe_indexing(y, target_class_indices)\n\u001B[0;32m    243\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mversion \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 244\u001B[0m     dist_vec, idx_vec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkneighbors\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    245\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_class\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_neighbors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_neighbors\u001B[49m\n\u001B[0;32m    246\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    247\u001B[0m     index_target_class \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_selection_dist_based(\n\u001B[0;32m    248\u001B[0m         X,\n\u001B[0;32m    249\u001B[0m         y,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    253\u001B[0m         sel_strategy\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnearest\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    254\u001B[0m     )\n\u001B[0;32m    255\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mversion \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\neighbors\\_base.py:822\u001B[0m, in \u001B[0;36mKNeighborsMixin.kneighbors\u001B[1;34m(self, X, n_neighbors, return_distance)\u001B[0m\n\u001B[0;32m    815\u001B[0m use_pairwise_distances_reductions \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    816\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbrute\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    817\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m ArgKmin\u001B[38;5;241m.\u001B[39mis_usable_for(\n\u001B[0;32m    818\u001B[0m         X \u001B[38;5;28;01mif\u001B[39;00m X \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meffective_metric_\n\u001B[0;32m    819\u001B[0m     )\n\u001B[0;32m    820\u001B[0m )\n\u001B[0;32m    821\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_pairwise_distances_reductions:\n\u001B[1;32m--> 822\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[43mArgKmin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    823\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mY\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_X\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_neighbors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meffective_metric_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetric_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meffective_metric_params_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mauto\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_distance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_distance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    830\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    832\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m (\n\u001B[0;32m    833\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbrute\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetric \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprecomputed\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m issparse(X)\n\u001B[0;32m    834\u001B[0m ):\n\u001B[0;32m    835\u001B[0m     results \u001B[38;5;241m=\u001B[39m _kneighbors_from_graph(\n\u001B[0;32m    836\u001B[0m         X, n_neighbors\u001B[38;5;241m=\u001B[39mn_neighbors, return_distance\u001B[38;5;241m=\u001B[39mreturn_distance\n\u001B[0;32m    837\u001B[0m     )\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:258\u001B[0m, in \u001B[0;36mArgKmin.compute\u001B[1;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001B[0m\n\u001B[0;32m    177\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute the argkmin reduction.\u001B[39;00m\n\u001B[0;32m    178\u001B[0m \n\u001B[0;32m    179\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    255\u001B[0m \u001B[38;5;124;03mreturns.\u001B[39;00m\n\u001B[0;32m    256\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    257\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m Y\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mfloat64:\n\u001B[1;32m--> 258\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mArgKmin64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    259\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    260\u001B[0m \u001B[43m        \u001B[49m\u001B[43mY\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    261\u001B[0m \u001B[43m        \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    262\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    263\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunk_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunk_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    264\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetric_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    265\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    266\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_distance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_distance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m Y\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mfloat32:\n\u001B[0;32m    270\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ArgKmin32\u001B[38;5;241m.\u001B[39mcompute(\n\u001B[0;32m    271\u001B[0m         X\u001B[38;5;241m=\u001B[39mX,\n\u001B[0;32m    272\u001B[0m         Y\u001B[38;5;241m=\u001B[39mY,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    278\u001B[0m         return_distance\u001B[38;5;241m=\u001B[39mreturn_distance,\n\u001B[0;32m    279\u001B[0m     )\n",
      "File \u001B[1;32msklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx:90\u001B[0m, in \u001B[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\utils\\fixes.py:72\u001B[0m, in \u001B[0;36mthreadpool_limits\u001B[1;34m(limits, user_api)\u001B[0m\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m controller\u001B[38;5;241m.\u001B[39mlimit(limits\u001B[38;5;241m=\u001B[39mlimits, user_api\u001B[38;5;241m=\u001B[39muser_api)\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mthreadpoolctl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthreadpool_limits\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlimits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muser_api\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_api\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\threadpoolctl.py:171\u001B[0m, in \u001B[0;36mthreadpool_limits.__init__\u001B[1;34m(self, limits, user_api)\u001B[0m\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, limits\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, user_api\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_limits, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_user_api, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prefixes \u001B[38;5;241m=\u001B[39m \\\n\u001B[0;32m    169\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_params(limits, user_api)\n\u001B[1;32m--> 171\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_set_threadpool_limits\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\threadpoolctl.py:268\u001B[0m, in \u001B[0;36mthreadpool_limits._set_threadpool_limits\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_limits \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    266\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 268\u001B[0m modules \u001B[38;5;241m=\u001B[39m \u001B[43m_ThreadpoolInfo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprefixes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prefixes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m                          \u001B[49m\u001B[43muser_api\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_user_api\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m    271\u001B[0m     \u001B[38;5;66;03m# self._limits is a dict {key: num_threads} where key is either\u001B[39;00m\n\u001B[0;32m    272\u001B[0m     \u001B[38;5;66;03m# a prefix or a user_api. If a module matches both, the limit\u001B[39;00m\n\u001B[0;32m    273\u001B[0m     \u001B[38;5;66;03m# corresponding to the prefix is chosed.\u001B[39;00m\n\u001B[0;32m    274\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m module\u001B[38;5;241m.\u001B[39mprefix \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_limits:\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\threadpoolctl.py:340\u001B[0m, in \u001B[0;36m_ThreadpoolInfo.__init__\u001B[1;34m(self, user_api, prefixes, modules)\u001B[0m\n\u001B[0;32m    337\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muser_api \u001B[38;5;241m=\u001B[39m [] \u001B[38;5;28;01mif\u001B[39;00m user_api \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m user_api\n\u001B[0;32m    339\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodules \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 340\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_modules\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    341\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_warn_if_incompatible_openmp()\n\u001B[0;32m    342\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\threadpoolctl.py:373\u001B[0m, in \u001B[0;36m_ThreadpoolInfo._load_modules\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    371\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_find_modules_with_dyld()\n\u001B[0;32m    372\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m sys\u001B[38;5;241m.\u001B[39mplatform \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwin32\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 373\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_find_modules_with_enum_process_module_ex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    374\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    375\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_find_modules_with_dl_iterate_phdr()\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\threadpoolctl.py:485\u001B[0m, in \u001B[0;36m_ThreadpoolInfo._find_modules_with_enum_process_module_ex\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    482\u001B[0m         filepath \u001B[38;5;241m=\u001B[39m buf\u001B[38;5;241m.\u001B[39mvalue\n\u001B[0;32m    484\u001B[0m         \u001B[38;5;66;03m# Store the module if it is supported and selected\u001B[39;00m\n\u001B[1;32m--> 485\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_module_from_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    486\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    487\u001B[0m     kernel_32\u001B[38;5;241m.\u001B[39mCloseHandle(h_process)\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\threadpoolctl.py:515\u001B[0m, in \u001B[0;36m_ThreadpoolInfo._make_module_from_path\u001B[1;34m(self, filepath)\u001B[0m\n\u001B[0;32m    513\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m prefix \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprefixes \u001B[38;5;129;01mor\u001B[39;00m user_api \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muser_api:\n\u001B[0;32m    514\u001B[0m     module_class \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mglobals\u001B[39m()[module_class]\n\u001B[1;32m--> 515\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[43mmodule_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muser_api\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minternal_api\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodules\u001B[38;5;241m.\u001B[39mappend(module)\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\threadpoolctl.py:606\u001B[0m, in \u001B[0;36m_Module.__init__\u001B[1;34m(self, filepath, prefix, user_api, internal_api)\u001B[0m\n\u001B[0;32m    604\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minternal_api \u001B[38;5;241m=\u001B[39m internal_api\n\u001B[0;32m    605\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dynlib \u001B[38;5;241m=\u001B[39m ctypes\u001B[38;5;241m.\u001B[39mCDLL(filepath, mode\u001B[38;5;241m=\u001B[39m_RTLD_NOLOAD)\n\u001B[1;32m--> 606\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mversion \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_version\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    607\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_threads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_num_threads()\n\u001B[0;32m    608\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_extra_info()\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\threadpoolctl.py:646\u001B[0m, in \u001B[0;36m_OpenBLASModule.get_version\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    643\u001B[0m get_config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dynlib, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mopenblas_get_config\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    644\u001B[0m                      \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    645\u001B[0m get_config\u001B[38;5;241m.\u001B[39mrestype \u001B[38;5;241m=\u001B[39m ctypes\u001B[38;5;241m.\u001B[39mc_char_p\n\u001B[1;32m--> 646\u001B[0m config \u001B[38;5;241m=\u001B[39m \u001B[43mget_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m()\n\u001B[0;32m    647\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOpenBLAS\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    648\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m config[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Modeling\n",
    "使用未经过重采样的数据集进行建模，作为baseline model，并与之后重采样的模型进行对比。\n",
    "\n",
    "准备使用的模型：Logistic Regression，Random Forest，XGBoost"
   ],
   "id": "4c2662b2e3b97a2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 Train Functions",
   "id": "f27a2d2688003d74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T07:45:18.712775Z",
     "start_time": "2024-07-18T07:45:18.708522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "def train_classifier(classifier, param_distributions, x_train_scaled, y_train, x_train_resampled, y_train_resampled, search_type='random', n_iter=50, cv=5, scoring='f1'):\n",
    "    \n",
    "    if search_type == 'random':\n",
    "        search_cv = RandomizedSearchCV(classifier, param_distributions, n_iter=n_iter, cv=cv, scoring=scoring, n_jobs=-1, random_state=42)\n",
    "    elif search_type == 'grid':\n",
    "        search_cv = GridSearchCV(classifier, param_distributions, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    else:\n",
    "        raise ValueError(\"search_type should be either 'random' or 'grid'\")\n",
    "    \n",
    "    # Train on the original (scaled) data\n",
    "    search_cv.fit(x_train_scaled, y_train)\n",
    "    best_model_original = search_cv.best_estimator_\n",
    "    \n",
    "    # Train on the resampled data\n",
    "    search_cv.fit(x_train_resampled, y_train_resampled)\n",
    "    best_model_resampled = search_cv.best_estimator_\n",
    "    \n",
    "    return best_model_original, best_model_resampled"
   ],
   "id": "ea3ec589be7a5aca",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T06:48:33.969264Z",
     "start_time": "2024-07-19T06:48:33.943265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_classifier(classifier, param_dist, X_train, y_train, encoded_features, search_type='random', scoring='roc_auc', resample_first=True, iterations=10):\n",
    "    \n",
    "    # 转换为numpy数组并确保数据类型高效\n",
    "    X_train = np.array(X_train).astype(np.float32)\n",
    "    y_train = np.array(y_train).astype(np.int32)\n",
    "    \n",
    "    # 创建交叉验证策略\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # 选择评分方法\n",
    "    if scoring == 'f1':\n",
    "        scoring_method = make_scorer(f1_score, pos_label=1)  # pos_label=1 表示正类标签为1\n",
    "    elif scoring == 'recall':\n",
    "        scoring_method = make_scorer(recall_score, pos_label=1)\n",
    "    else:\n",
    "        scoring_method = scoring\n",
    "\n",
    "    # 构建采样和模型管道\n",
    "    smote_nc = SMOTENC(categorical_features=encoded_features, sampling_strategy='minority', random_state=42, n_jobs=-1)\n",
    "    if resample_first:\n",
    "        X_train, y_train = smote_nc.fit_resample(X_train, y_train)\n",
    "        pipeline = make_pipeline(classifier)\n",
    "    else:\n",
    "        pipeline = make_pipeline(smote_nc, classifier)\n",
    "    \n",
    "    # 进行超参数搜索\n",
    "    if search_type == 'random':\n",
    "        search_cv = RandomizedSearchCV(estimator=pipeline, \n",
    "                                       param_distributions=param_dist,\n",
    "                                       n_iter=iterations,\n",
    "                                       scoring=scoring_method,\n",
    "                                       n_jobs=-1,\n",
    "                                       cv=cv,\n",
    "                                       verbose=2)\n",
    "    elif search_type == 'grid':\n",
    "        search_cv = GridSearchCV(estimator=pipeline,\n",
    "                                 param_grid=param_dist,\n",
    "                                 scoring=scoring_method,\n",
    "                                 n_jobs=-1,\n",
    "                                 cv=cv,\n",
    "                                 verbose=2)\n",
    "    else:\n",
    "        raise ValueError('search_type 必须是 \"random\" 或 \"grid\"')\n",
    "        \n",
    "    # 拟合模型并返回训练好的分类器\n",
    "    search_cv.fit(X_train, y_train)\n",
    "\n",
    "    return search_cv"
   ],
   "id": "af2301e40c889827",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 Evaluate Functions",
   "id": "73dfb7801c15d9ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T06:28:01.097022Z",
     "start_time": "2024-07-19T06:28:01.081994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print classification report\n",
    "def print_cls_report(y_test, y_pred, title=\"Classification Report\"):\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    recall = report[\"1\"][\"recall\"]\n",
    "    print(f\"{title}:\\n\", classification_report(y_test, y_pred))\n",
    "    return recall\n",
    "\n",
    "# plot confusion matrix\n",
    "def plot_con_matrix(ax, y_test, y_pred, title):\n",
    "    # Define the classes of the classification problem\n",
    "    classes = ['No Fraud', 'Fraud']\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    con_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Compute the values for true negatives, false positives, false negatives, and true positives\n",
    "    tn, fp, fn, tp = con_matrix.ravel()\n",
    "\n",
    "    # Compute the false positive rate\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    # Plot the confusion matrix using a heatmap\n",
    "    ax.imshow(con_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "    # Define the tick marks and the labels for the plot\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_yticklabels(classes)\n",
    "\n",
    "    # Add the count of each cell of the confusion matrix to the plot\n",
    "    fmt = 'd'\n",
    "    threshold = con_matrix.max() / 2.\n",
    "    for i, j in np.ndindex(con_matrix.shape):\n",
    "        ax.text(j, i, format(con_matrix[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if con_matrix[i, j] > threshold else \"black\")\n",
    "\n",
    "    # Add labels to the plot\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_title(f'{title} with {fpr*100:.2f}% FPR')"
   ],
   "id": "bf5da4415f24b520",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T06:28:18.540647Z",
     "start_time": "2024-07-19T06:28:18.514201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# labels = y_test\n",
    "groups = (x_test[\"customer_age\"] > 50).map({True: \">50\", False: \"<=50\"}) \n",
    "\n",
    "def get_fairness_metrics(y_true, y_pred, groups, FIXED_FPR):\n",
    "    g = Group()\n",
    "    aequitas_df = pd.DataFrame(\n",
    "        {\"score\": y_pred,\n",
    "         \"label_value\": y_true,\n",
    "         \"group\": groups}\n",
    "    )\n",
    "    disparities_df = g.get_crosstabs(aequitas_df, score_thresholds={\"score_val\": [FIXED_FPR]})[0]\n",
    "    predictive_equality = disparities_df[\"fpr\"].min() / disparities_df[\"fpr\"].max()\n",
    "    return predictive_equality, disparities_df\n",
    "\n",
    "def evaluate_classifier(classifier, x_train,y_train,x_test, y_test, groups):\n",
    "    y_train_pred = classifier.predict(x_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    y_prob = classifier.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "    target_fpr = 0.05  # Set the target threshold at 5% FPR\n",
    "    threshold_idx = np.argmin(np.abs(fpr - target_fpr))\n",
    "    threshold = thresholds[threshold_idx]\n",
    "    \n",
    "    y_pred_threshold = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    train_set = print_cls_report(y_train, y_train_pred, title=\"Train Set\")\n",
    "    default_recall = print_cls_report(y_test, y_pred, title=\"Default Threshold\")\n",
    "    target_recall = print_cls_report(y_test, y_pred_threshold, title=f'Target Threshold @ {threshold:.2f}')\n",
    "    \n",
    "     # Calculate predictive equality\n",
    "    predictive_equality, disparities_df = get_fairness_metrics(y_test, y_pred_threshold, groups, target_fpr)\n",
    "    print(f\"Predictive Equality: {predictive_equality:.2f}\")\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    default_matrix = plot_con_matrix(ax1, y_test, y_pred, title='Default Threshold @ 0.50')\n",
    "    target_matrix = plot_con_matrix(ax2, y_test, y_pred_threshold, title=f'Target Threshold @ {threshold:.2f}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return fpr, tpr, default_recall, target_recall, predictive_equality"
   ],
   "id": "61f8da44739118d",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 Random Forest",
   "id": "fd1a1ef234f0c84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T06:42:19.414040Z",
     "start_time": "2024-07-19T06:42:14.843653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "# Define a dictionary of hyperparameters for RandomForestClassifier\n",
    "rf_params = {'randomforestclassifier__n_estimators': [20, 40, 60, 80, 100],\n",
    "            'randomforestclassifier__criterion': ['gini', 'entropy'],\n",
    "            'randomforestclassifier__max_depth': [2, 4, 6, 8, 10],\n",
    "            'randomforestclassifier__max_features': ['sqrt', 'log2']\n",
    "            }\n",
    "\n",
    "rf_model = train_classifier(rf, rf_params, x_train_scaled, y_train, categorical_feature_indices, search_type='random', scoring='recall')"
   ],
   "id": "2882c5c3dcb4c1b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n100 fits failed with the following error:\nTraceback (most recent call last):\n  File \"E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\pipeline.py\", line 416, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\pipeline.py\", line 350, in _fit\n    self._validate_steps()\n  File \"E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\pipeline.py\", line 234, in _validate_steps\n    raise TypeError(\nTypeError: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTENC(categorical_features=[13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n                              25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n                              37, 38, 39, 40, 41, 42, ...],\n        random_state=42, sampling_strategy='minority')' (type <class 'imblearn.over_sampling._smote.base.SMOTENC'>) doesn't\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[90], line 10\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Define a dictionary of hyperparameters for RandomForestClassifier\u001B[39;00m\n\u001B[0;32m      4\u001B[0m rf_params \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrandomforestclassifier__n_estimators\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m20\u001B[39m, \u001B[38;5;241m40\u001B[39m, \u001B[38;5;241m60\u001B[39m, \u001B[38;5;241m80\u001B[39m, \u001B[38;5;241m100\u001B[39m],\n\u001B[0;32m      5\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrandomforestclassifier__criterion\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgini\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mentropy\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m      6\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrandomforestclassifier__max_depth\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m6\u001B[39m, \u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m10\u001B[39m],\n\u001B[0;32m      7\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrandomforestclassifier__max_features\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msqrt\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlog2\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      8\u001B[0m             }\n\u001B[1;32m---> 10\u001B[0m rf_model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_classifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrf_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcategorical_feature_indices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msearch_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrandom\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrecall\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[89], line 32\u001B[0m, in \u001B[0;36mtrain_classifier\u001B[1;34m(classifier, param_dist, X_train, y_train, encoded_features, search_type, scoring)\u001B[0m\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msearch_type must be either \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrandom\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrid\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# Fit the model and return the trained classifier\u001B[39;00m\n\u001B[1;32m---> 32\u001B[0m \u001B[43msearch_cv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m search_cv\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1149\u001B[0m     )\n\u001B[0;32m   1150\u001B[0m ):\n\u001B[1;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    892\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    893\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    894\u001B[0m     )\n\u001B[0;32m    896\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 898\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    900\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    901\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    902\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1806\u001B[0m, in \u001B[0;36mRandomizedSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1804\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1805\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1806\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1807\u001B[0m \u001B[43m        \u001B[49m\u001B[43mParameterSampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1808\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_distributions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\n\u001B[0;32m   1809\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1810\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m!=\u001B[39m n_candidates \u001B[38;5;241m*\u001B[39m n_splits:\n\u001B[0;32m    869\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    870\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcv.split and cv.get_n_splits returned \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    871\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minconsistent results. Expected \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    872\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplits, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(n_splits, \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m n_candidates)\n\u001B[0;32m    873\u001B[0m     )\n\u001B[1;32m--> 875\u001B[0m \u001B[43m_warn_or_raise_about_fit_failures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;66;03m# For callable self.scoring, the return type is only know after\u001B[39;00m\n\u001B[0;32m    878\u001B[0m \u001B[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001B[39;00m\n\u001B[0;32m    879\u001B[0m \u001B[38;5;66;03m# can now be inserted with the correct key. The type checking\u001B[39;00m\n\u001B[0;32m    880\u001B[0m \u001B[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001B[39;00m\n\u001B[0;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring):\n",
      "File \u001B[1;32mE:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001B[0m, in \u001B[0;36m_warn_or_raise_about_fit_failures\u001B[1;34m(results, error_score)\u001B[0m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_failed_fits \u001B[38;5;241m==\u001B[39m num_fits:\n\u001B[0;32m    408\u001B[0m     all_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    409\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAll the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    410\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt is very likely that your model is misconfigured.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    411\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can try to debug the error by setting error_score=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    412\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    413\u001B[0m     )\n\u001B[1;32m--> 414\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(all_fits_failed_message)\n\u001B[0;32m    416\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    417\u001B[0m     some_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    418\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mnum_failed_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed out of a total of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    419\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe score on these train-test partitions for these parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    423\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    424\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: \nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n100 fits failed with the following error:\nTraceback (most recent call last):\n  File \"E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\pipeline.py\", line 416, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\pipeline.py\", line 350, in _fit\n    self._validate_steps()\n  File \"E:\\Programming\\anaconda3\\envs\\mytorch\\lib\\site-packages\\sklearn\\pipeline.py\", line 234, in _validate_steps\n    raise TypeError(\nTypeError: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTENC(categorical_features=[13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n                              25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n                              37, 38, 39, 40, 41, 42, ...],\n        random_state=42, sampling_strategy='minority')' (type <class 'imblearn.over_sampling._smote.base.SMOTENC'>) doesn't\n"
     ]
    }
   ],
   "execution_count": 90
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
